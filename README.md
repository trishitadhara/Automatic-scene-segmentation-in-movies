# Automatic-scene-segmentation-in-movies
## Introduction
With applications in the entertainment sector including scene retrieval and video editing, movie scene segmentation is a difficult computer vision problem. A scene is made up of one or more shots that are connected in terms of time, place, and theme. A shot is a continuous series of images, whereas a scene is a higher-level semantic unit. Although there has been a lot of research on scene boundary detection in videos, there is still room for improvement. Scene boundary detection methods such as shot contrastive learning and supervised classification have recently been proposed, but they have drawbacks. In this study, the we suggest tackling the issue of movie scene recognition by replacing sub-problems with cutting-edge models to enhance the precision and effectiveness of current deep-learning models. 
## Running the Code 
### Data Collection
To run the code, you need to download the movienet dataset from https://opendatalab.com/MovieNet/download, and also labels from https://drive.google.com/drive/folders/1w_qdnRsxF1w1rMuMbdCe1JLHeZ0MZ6A8 
### Running

## Contribution
## References
@inproceedings{rao2020local,
title={A Local-to-Global Approach to Multi-modal Movie Scene Segmentation},
author={Rao, Anyi and Xu, Linning and Xiong, Yu and Xu, Guodong and Huang, Qingqiu and Zhou, Bolei and Lin, Dahua},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2020}
}

https://github.com/AnyiRao/SceneSeg

https://github.com/movienet
